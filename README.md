## Capstone - Cyrano: Improving Couples' Communication Through Empathetic Dialogue

Additional Participants: Joe Mirza, Ziwei Zhao

# Introduction
This was the final capstone project for my Master's in Information and Data Science at UC Berkeley. The purpose of this code is to leverage an existing chatbot from Huggingface (original source here: https://github.com/huggingface/transfer-learning-conv-ai) and alter its text selection process in order to try and alter pre-existing messages to try and rewrite them in a more empathetic manner. All changes to the code compared to this source are my own, save for where I have annotated them as being done by one of the two additional participants.

# Overview of Methodology
The way in which empathy was assessed was using unigram empathy ratings taken from this paper: https://arxiv.org/pdf/1912.01079v2.pdf. The paper describes the dataset as, "first publicly available gold standard dataset supported by proper psychological theories. The dataset consists of responses to news articles and scales for empathy and distress between 1 and 7." As it suggests, a team of psychologists labeled a dataset of news comments under news articles and assigned an empathy score between 1 and 7. Essentially the sentences and the ratings were fed through a feed-forward network which learned unigram-level emapthy ratings which were then used by my capstone team and myself for the purposes of this task.

The main files that were edited from the original chatbot code were what was what called the "interact.py" script, which is where the original code called GPT to select the next tokens to generate text in the given context. For the purposes of our task, our final demonstartion involved a framework of using one message from a hypothetical conversation partner as context, and a message from a hypothetical user of a service based on our script which would first be evaluated for empathy. If the mean empathy of the tokens in the sentence is below 3.5 (or neutral empathy on a 1 to 7 scale), the chatbot would attempt to rewrite the sentence to improve the empathy, given the partner's previous message as context.

There are two versions of the original interact.py script here, interact_top20_formatted_v2.py and interact_experiment.py. The interact_top20 version was the script used for the UX interface shown in the final demonstartion for this capstone as it performed better in more versatile scenarios. However a lot of work went into interact_experiment.py so it is included in this repositroy and I will explain how it works as well. 

# Interact_top20 Methodology
Interact_top20 is a more naive approach to rewriting a sentence in a more empathetic manner. As mentioned before we first take a look at the user's hypothetical message and calculate the empathy of each of the unigrams in the sentence. IF the mean empathy is below 3.5, in this script, the sentence segment is then cut off to the token prior to the least emapthetic token in the original sentence. The original chatbot from huggingface used GPT as the tool for generating text. So given the previous message from the partner and the sentence segment up to the least empathetic token, GPT sorts through its massive corpus and training data to predict a vector of tokens that it thinks would follow this sequence, which is sorted by the probability. We then have GPT make a list of the top 20 most likely tokens to follow this sequence, and we evaluate the unigram-level empathy of each of these tokens. We then force GPT to select the highest empathy token from among these. 

For the purposes of evaluation, the team (mostly myself, Ziwei Zhao, and a family member of mine) came up with 100 hypothetical exchanges in which the partner would send what we considered a normal message that could arise in a couple's conversation and the service user originally wrote what we considered to be a very unemapthetic response. The actual model evaluation process was largely assessed by Ziwei Zhao. Of these 100, 13 the model didn't attempt to rewrite because the original resposne was considered empathetic enough already. Of the sentences that were rewritten, the median sentence's emapthy score improved by 0.22, but as Ziwei noted, higher empathy did not mean a human would consider the sentence more empathetic as unigram-level empathy is somewhat naive. Based on the evaluation criteria Ziwei defined, in about 40% of these use cases, the model here produced sentences that a human evaluator (namely Ziwei) considered more empathetic with an adequate level of fluency (i.e. no major grammatical errors or typos) and relevancy (made sense in the context and would not confuse a hypothetical recepient in the context). 

# Interact_experiment methodology
The interact_experiment approach was a more statistically robust approach comapred to the more naive top 20 approach. The idea was to run a series of example prompts into the setup in interact_top20 but instead of generating only one sentence using the most empathetic token among the 20 most likely to follow the sequence, the chatbot would generate one sentence for all 20 of these tokens. Ziwei and I then reviewed all of these 20 sentences and picked out the ones we thought were best from a human perspective. We collected their values for relevancy (i.e. the distance in vector space from the user's original intended resposne using the universal sentence encoder), fluency (the sentence's perplexity), and empathy (using the aforementioned mean empathy fo tokens methodology). We then used the metrics of these examples of "good" sentences as the basis for a Mahalanobis distance algorithm. Mahalanobis distance differs from euclidean distance in that it does not assign equal weight to every dimension of vector space, it learns to weight different dimensions more based on training data of desired outcomes so as to weigh dimensions more that delineate good from poor outcomes in vector space. Interact_experiment essentially has the chatbto generate 20 versions of a rewritten resposne to the original user's message and then selects the one that is closest to the examples of good sentences invector space by these three metrics. The main issue was the team could only find about 80 examples of "good" sentences, and so there was very limited training data underlying this Mahalanobis distance metric and the results were rather poor in testing compared to the interact_top20 method. My personal opinion is if there was more time and money to collect examplesa of "good" sentences, this method could be more optimal for this task at scale.

# Replication Instructions
If you wish to run these codes for yourself, first clone the repository into a machine, preferably one with a GPU (we primarily ran these codes on an AWS g4dn.4xlarge instance during testing). Then run the following lines from the command line:

1. docker build -t convai --no-cache .

2. docker run --rm -it convai bash

3. python3 interact_top20_formatted_v2.py --model openai-gpt


If you wish to run interact_experiment instead, change the 3rd line to:
 - python3 interact_experiment.py --model openai-gpt

Please note that the first prompt will be for the original recieved message, this will onyl be used for context by GPT, and will not be evaluated for empathy or be rewritten. It is the message you type in the second response which should be a response to the first prompt that will be evaluated for empathy and rewritten. 
