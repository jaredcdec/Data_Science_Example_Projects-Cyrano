# Capstone - Cyrano: Improving Couples' Communication Through Empathetic Dialogue

Additional Participants: Joe Mirza, Ziwei Zhao

This was the final capstone project for my Master's in Information and Data Science at UC Berkeley. The purpose of this code is to leverage an existing chatbot from Huggingface (original source here: https://github.com/huggingface/transfer-learning-conv-ai) and alter its text selection process in order to try and alter pre-existing messages to try and rewrite them in a more emapthetic manner. All changes to the code compared to this source are my own, save for where I have annotated them as being done by one of the two additional participants.

The way in which empathy was assessed was using unigram empathy ratings taken from this paper: https://arxiv.org/pdf/1912.01079v2.pdf. The paper describes the dataset as, "first publicly available gold standard dataset supported by proper psychological theories. The dataset consists of responses to news articles and scales for empathy and distress between 1 and 7." As it suggests, a team of psychologists labeled a dataset of news comments under news articles and assigned an empathy score between 1 and 7. Essentially the sentences and the ratings were fed through a feed-forward network which learned unigram-level emapthy ratings which were then used by my capstone team and myself for the purposes of this task.

The main files that were edited from the original chatbot code were what was what called the "interact.py" script, which is where the original code called GPT to select the next tokens to generate text in the given context. For the purposes of our task, our final demonstartion involved a framework of using one message from a hypothetical conversation partner as context, and a message from a hypothetical user of a service based on our script which would first be evaluated for empathy. If the mean empathy of the tokens in the sentence is below 3.5 (or neutral empathy on a 1 to 7 scale), the chatbot would attempt to rewrite the sentence to improve the empathy, given the partner's previous message as context.

There are two versions of the original interact.py script here, interact_top20_formatted_v2.py and interact_experiment.py. The interact_top20 version was the script used for the UX interface shown in the final demonstartion for this capstone as it performed better in more versatile scenarios. However a lot of work went into interact_experiment.py so it is included in this repositroy and I will explain how it works as well. 

Interact_top20 is a more naive approach to rewriting a sentence in a more empathetic manner. As mentioned before we first take a look at the user's hypothetical message and calculate the empathy of each of the unigrams in the sentence. IF the mean empathy is below 3.5, in this script, the sentence segment is then cut off to the token prior to the least emapthetic token in the original sentence. The original chatbot from huggingface used GPT as the tool for generating text. So given the previous message from the partner and the sentence segment up to the least empathetic token, GPT sorts through its massive corpus and training data to predict a vector of tokens that it thinks would follow this sequence, which is sorted by the probability. We then have GPT make a list of the top 20 most likely tokens to follow this sequence, and we evaluate the unigram-level empathy of each of these tokens. We then force GPT to select the highest empathy token from among these. 

For the purposes of evaluation, the team (mostly myself, Ziwei Zhao, and a family member of mine) came up with 100 hypothetical exchanges in which the partner would send what we considered a normal message that could arise in a couple's conversation and the service user originally wrote what we considered to be a very unemapthetic response. The actual model evaluation process was largely assessed by Ziwei Zhao. Of these 100, 13 the model didn't attempt to rewrite because the original resposne was considered empathetic enough already. Of the sentences that were rewritten, the median sentence's emapthy score improved by 0.22, but as Ziwei noted, higher empathy did not mean a human would consider the sentence more empathetic as unigram-level empathy is somewhat naive. Based on the evaluation criteria Ziwei defined, in about 40% of these use cases, the model here produced sentences that a human evaluator (namely Ziwei) considered more empathetic with an adequate level of fluency (i.e. no major grammatical errors or typos) and relevancy (made sense in the context and would not confuse a hypothetical recepient in the context). 

